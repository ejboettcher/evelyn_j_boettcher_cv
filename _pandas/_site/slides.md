## Processing Large Data with Pandas

### By Evelyn J. Boettcher

#### DiDacTex, LLC

<br/>


### Link to Repo

[https://github.com/DiDacTexGit/Talk-ProcessingLargeDatawithPandas](https://github.com/DiDacTexGit/Talk-ProcessingLargeDatawithPandas)

---

## Motivation
Data sets can get large quickly.  
You can quickly go from looking at a few 100 lines and a handful of columns to a million lines and hundred of columns.  

Luckily, we live in a time where most people have laptops with processing power 
that would have made the engineers who put a man on the moon swoon. 
At the very least, doubt it would be possible to make.

<br/>

### But, you say,

#### "My data is BIG data, so I neeeed a better computer."
Well this talk is for you.

---

## Brief History (small subset) of Large Data


As soon as there was paper and pen, 
<br/> there has been large data sets.

For example, in the 1600 Johannes Kepler used Tycho Brahe large data set on planet observations to prove how planets orbit the sun.  

<br/>

Unfortunately, he had to wait until Tycho Brahe died before he could get a hold of a large data set.  
<br/>



#### Many thought he played a hand in Brahe's death

---

## Brief  History (small subset) of Large Data cont.

And in 1676 Ole Roemer (RÃ¸mer) armed with only paper, pencil, telescope and 
a wind up watch (which was not even good enough to navigate a ship with) 
calculated the speed of LIGHT within 30% by looking at Jupiter's moon Io.  

(NOTE: prior to this people thought that light was instantaneous!  
His prediction for Io was off by a few minutes.)

 <br/>
 
#### Only equipment needed to measure speed of light
<br/>
